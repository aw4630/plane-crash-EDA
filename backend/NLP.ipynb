{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script utilizes the OpenAI API (GPT-3.5-turbo model) LLM to perform NLP in the form of text classification. I make the API go through the entire \"Narrative\" column, extracting the text for each entry to determine the cause of the aircraft incident. All entries will fall in these specific categories:\n",
    "- Pilot error\n",
    "- Mechanical failure\n",
    "- Weather\n",
    "- ATC error\n",
    "- Sabotage\n",
    "- Other\n",
    "- Unknown\n",
    "\n",
    "I have provided category descriptions to give the LLM more context to improve the accruacy of the text classification. After categorizing the text data, I put the results into a list and go to the \"cleaned_asndb.csv\" file and append the new \"Primary causes\" column into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai==0.28 in /opt/anaconda3/lib/python3.11/site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/anaconda3/lib/python3.11/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.11/site-packages (from openai==0.28) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/lib/python3.11/site-packages (from openai==0.28) (3.9.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp->openai==0.28) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classifying Narratives: 100%|██████████| 693/693 [17:33<00:00,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification complete. The final CSV has been saved as 'final_asndb.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "%pip install openai==0.28\n",
    "import openai\n",
    "#print(openai.__version__)\n",
    "\n",
    "# Set up with my key\n",
    "openai.api_key = \"MY_API_KEY\" ##<< API KEY HIDDEN FOR PRIVACY\n",
    "\n",
    "\n",
    "#Load the narrative.csv file created specific to read the narrative texts\n",
    "narrative_df = pd.read_csv('narrative.csv')\n",
    "narrative_df['Narrative'] = narrative_df['Narrative'].fillna('')\n",
    "\n",
    "# GIVE MORE INFO TO GPT-3.5 LLM to improve NLP\n",
    "category_descriptions = {\n",
    "    'Pilot error': \"\"\"\n",
    "    Errors in judgment, decision-making, or action by the flight crew. \n",
    "    This includes failure to follow procedures and protocol, mishandling of aircraft controls, \n",
    "    miscommunication, navigation errors, spatial disorientation, fatigue-related mistakes, or inadequate preparation.\n",
    "    \"\"\",\n",
    "    'Mechanical failure': \"\"\"\n",
    "    Malfunctions or failures of aircraft systems, engines, or components. \n",
    "    This includes issues with engines, landing gear, hydraulics, electrical and computer systems, \n",
    "    or structural failures not caused by external factors.\n",
    "    \"\"\",\n",
    "    'Weather': \"\"\"\n",
    "    Adverse weather conditions. This includes \n",
    "    thunderstorms, icing, turbulence, low visibility, fog, wind shear, or any \n",
    "    weather phenomenon that caused aircraft to crash.\n",
    "    \"\"\",\n",
    "    'ATC error': \"\"\"\n",
    "    Errors caused by air traffic control miscommunication or mistakes. ATC must be the primary cause.\n",
    "    \"\"\",\n",
    "    'Sabotage': \"\"\"\n",
    "    Intentional actions to damage or compromise the safety of the aircraft. \n",
    "    This includes terrorist acts, hijackings, explosives, explosions, bombings, pilot suicide, or any deliberate \n",
    "    interference with the aircraft's systems or operation.\n",
    "    \"\"\",\n",
    "    'Other': \"\"\"\n",
    "    Causes that don't fit into the above categories. This might include \n",
    "    bird strikes, ground collisions, ground crew issues, heart attacks, a single pilot/passenger random death, or rare events like space debris impact.\n",
    "    \"\"\",\n",
    "    'Unknown': \"\"\"\n",
    "    Cases where the cause cannot be determined or is not clearly stated \n",
    "    in the available information, disappeared aircraft not found\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "category_descriptions_str = \"\\n\".join([f\"{k}: {v.strip()}\" for k, v in category_descriptions.items()])\n",
    "\n",
    "# PROMPT\n",
    "def classify_narrative(narrative):\n",
    "    prompt = f\"\"\"Classify the following aircraft incident narrative into one of these categories, do not give an explanation just the category name, the only values outputted should be part of this list:\n",
    "{category_descriptions_str}\n",
    "\n",
    "Narrative: {narrative}\n",
    "\n",
    "Category:\"\"\"\n",
    "    \n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    category = response['choices'][0]['message']['content'].strip()\n",
    "    return category\n",
    "\n",
    "primary_causes = []\n",
    "\n",
    "# Loop through each narrative and classify it\n",
    "for narrative in tqdm(narrative_df['Narrative'], desc=\"Classifying Narratives\"):\n",
    "    primary_cause = classify_narrative(narrative)\n",
    "    primary_causes.append(primary_cause)\n",
    "    time.sleep(1)  # Add a delay to avoid rate limiting/ API has certain requests per minute\n",
    "   \n",
    "narrative_df['Primary cause'] = primary_causes\n",
    "\n",
    "# Load the original 'final_asndb.csv' file\n",
    "final_df = pd.read_csv('final_asndb.csv')\n",
    "\n",
    "# Make sure rows match with original narrative.csv df\n",
    "if len(final_df) == len(narrative_df):\n",
    "    # Append primary cause column\n",
    "    final_df['Primary cause'] = narrative_df['Primary cause']\n",
    "    \n",
    "    final_df.to_csv('final_asndb.csv', index=False)\n",
    "    print(\"text classification complete. The final CSV has been saved as 'final_asndb.csv'.\")\n",
    "else:\n",
    "    print(\"Error: The # of rows in 'final_asndb.csv' and 'narrative.csv' doesn't match.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I perform further cleaning of this .csv file into a final form to be used by my PostgreSQL database. This is the .csv that is extracted into the SQL database, allowing queries from the frontend of my webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('final_asndb.csv')\n",
    "\n",
    "# Convert date column, should be MM-DD-YYYY to be compatible with SQL \"date\" classification\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%A %d %B %Y').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Make sure time column is in HH:MM:SS format\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%H:%M', errors='coerce').dt.strftime('%H:%M:%S')\n",
    "\n",
    "# Save the cleaned CSV\n",
    "df.to_csv('final_cleaned_asndb.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
